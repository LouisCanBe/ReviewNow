import streamlit as st
import pandas as pd
import os
import json
import re
import requests
import urllib.parse
from arxiv_client import ArxivClient
from paper_manager import PaperManager
from translate import Translator
from streamlit.runtime.scriptrunner import add_script_run_ctx, get_script_run_ctx
import threading
import time

# å®‰å…¨çš„è·å–å­—å…¸å€¼çš„å‡½æ•°
def safe_get(dictionary, key, default=""):
    """å®‰å…¨åœ°ä»å­—å…¸ä¸­è·å–å€¼ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å€¼"""
    if not isinstance(dictionary, dict):
        return default
    return dictionary.get(key, default)

# åˆå§‹åŒ–ArxivClientå’ŒPaperManager
arxiv_client = ArxivClient()
paper_manager = PaperManager()

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="ArXivç»¼è¿°æ•´ç†å·¥å…·", layout="wide")
st.title("ArXiv ç»¼è¿°æ•´ç†å·¥å…·")

# åˆ›å»ºä¾§è¾¹æ ï¼Œç”¨äºåˆ‡æ¢åŠŸèƒ½
st.sidebar.title("åŠŸèƒ½")
option = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½", ["æœç´¢è®ºæ–‡", "ä¸‹è½½è®ºæ–‡", "æ•´ç†è®ºæ–‡"])

# åˆ¤æ–­æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡
def contains_chinese(text):
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
    return bool(re.search(r'[\u4e00-\u9fff]', text))

# ä½¿ç”¨Google Translateè¿›è¡Œç¿»è¯‘ï¼ˆæ— éœ€APIå¯†é’¥çš„æ–¹æ³•ï¼‰
def google_translate(text, to_lang="en", from_lang="zh"):
    """ä½¿ç”¨Google Translate APIè¿›è¡Œç¿»è¯‘ï¼ˆæ— éœ€APIå¯†é’¥ï¼‰"""
    try:
        # æ„å»ºURL
        url = "https://translate.googleapis.com/translate_a/single"
        params = {
            "client": "gtx",  # ä½¿ç”¨gtxä½œä¸ºå®¢æˆ·ç«¯ï¼Œä¸éœ€è¦APIå¯†é’¥
            "dt": "t",        # è¡¨ç¤ºæˆ‘ä»¬åªéœ€è¦ç¿»è¯‘
            "sl": from_lang,  # æºè¯­è¨€
            "tl": to_lang,    # ç›®æ ‡è¯­è¨€
            "q": text         # è¦ç¿»è¯‘çš„æ–‡æœ¬
        }
        
        # å‘é€è¯·æ±‚
        encoded_params = urllib.parse.urlencode(params)
        full_url = f"{url}?{encoded_params}"
        response = requests.get(full_url, timeout=5)
        
        if response.status_code != 200:
            print(f"Googleç¿»è¯‘è¯·æ±‚å¤±è´¥: {response.status_code}")
            return text
        
        # è§£æå“åº”ï¼ˆGoogle Translateè¿”å›çš„æ˜¯åµŒå¥—åˆ—è¡¨ï¼‰
        result = response.json()
        # ç¬¬ä¸€ä¸ªåˆ—è¡¨åŒ…å«ç¿»è¯‘ç»“æœï¼Œæˆ‘ä»¬éœ€è¦åˆå¹¶æ‰€æœ‰ç¿»è¯‘ç‰‡æ®µ
        translated_text = ""
        for sentence in result[0]:
            if sentence[0]:
                translated_text += sentence[0]
        
        return translated_text
    except Exception as e:
        print(f"Googleç¿»è¯‘å‡ºé”™: {str(e)}")
        return text

# æ”¹è¿›çš„ç¿»è¯‘å‡½æ•°ï¼Œå¸¦å¤‡ç”¨æ–¹æ³•
def translate_to_english(text):
    """å°†ä¸­æ–‡æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼Œå¸¦å¤‡ç”¨æ–¹æ³•"""
    if not contains_chinese(text):
        return text, False  # ä¸åŒ…å«ä¸­æ–‡ï¼Œæ— éœ€ç¿»è¯‘
    
    try:
        # é¦–å…ˆå°è¯•åŸå§‹ç¿»è¯‘æ–¹æ³•
        translator = Translator(to_lang="en", from_lang="zh")
        translated = translator.translate(text)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºé”™è¯¯ä¿¡æ¯
        if "MYMEMORY WARNING" in translated.upper() or "QUOTA EXCEEDED" in translated.upper():
            print("ä¸»è¦ç¿»è¯‘APIé…é¢å·²ç”¨å®Œï¼Œåˆ‡æ¢åˆ°Googleç¿»è¯‘")
            # ä½¿ç”¨å¤‡ç”¨Googleç¿»è¯‘
            translated = google_translate(text, to_lang="en", from_lang="zh")
            return translated, True
        
        return translated, True
        
    except Exception as e:
        print(f"ä¸»è¦ç¿»è¯‘æ–¹æ³•å¤±è´¥: {str(e)}ï¼Œåˆ‡æ¢åˆ°Googleç¿»è¯‘")
        # ä½¿ç”¨å¤‡ç”¨Googleç¿»è¯‘
        try:
            translated = google_translate(text, to_lang="en", from_lang="zh")
            return translated, True
        except Exception as backup_e:
            print(f"å¤‡ç”¨ç¿»è¯‘ä¹Ÿå¤±è´¥: {str(backup_e)}")
            return text, False

# åœ¨app.pyçš„å¼€å¤´åˆå§‹åŒ–éƒ¨åˆ†æ·»åŠ 
if 'download_states' not in st.session_state:
    st.session_state.download_states = {}
if 'download_messages' not in st.session_state:
    st.session_state.download_messages = {}

# æ·»åŠ å¼‚æ­¥ä¸‹è½½å‡½æ•°
def download_paper_async(paper_id):
    """å¼‚æ­¥ä¸‹è½½è®ºæ–‡ï¼Œä¸é˜»å¡UI"""
    try:
        # æ›´æ–°ä¸‹è½½çŠ¶æ€ä¸º"æ­£åœ¨ä¸‹è½½"
        st.session_state.download_states[paper_id] = "downloading"
        st.session_state.download_messages[paper_id] = "æ­£åœ¨ä¸‹è½½è®ºæ–‡..."
        
        # æ‰§è¡Œä¸‹è½½
        output_path = arxiv_client.download(paper_id)
        
        # æ£€æŸ¥ä¸‹è½½ç»“æœ
        if isinstance(output_path, dict) and "error" in output_path:
            st.session_state.download_states[paper_id] = "error"
            st.session_state.download_messages[paper_id] = f"ä¸‹è½½å¤±è´¥: {output_path['error']}"
        else:
            # ä¸‹è½½æˆåŠŸ
            st.session_state.download_states[paper_id] = "success"
            st.session_state.download_messages[paper_id] = f"ä¸‹è½½æˆåŠŸ: {output_path}"
            
            # æ·»åŠ åˆ°è®ºæ–‡ç®¡ç†å™¨
            try:
                paper = arxiv_client.get_paper_details(paper_id)
                paper_manager.add_paper(paper, output_path)
                st.session_state.download_messages[paper_id] += " (å·²æ·»åŠ åˆ°è®ºæ–‡ç®¡ç†å™¨)"
            except Exception as add_err:
                st.session_state.download_messages[paper_id] += f" (æ·»åŠ åˆ°ç®¡ç†å™¨å¤±è´¥: {str(add_err)})"
    
    except Exception as e:
        st.session_state.download_states[paper_id] = "error"
        st.session_state.download_messages[paper_id] = f"ä¸‹è½½å‡ºé”™: {str(e)}"

# æ ¹æ®é€‰æ‹©çš„åŠŸèƒ½æ˜¾ç¤ºä¸åŒçš„å†…å®¹
if option == "æœç´¢è®ºæ–‡":
    st.header("æœç´¢ArXivè®ºæ–‡")
    
    # åœ¨é€‰æ‹©è®ºæ–‡çš„éƒ¨åˆ†
    if 'selected_paper_id' not in st.session_state:
        st.session_state.selected_paper_id = None

    # æœç´¢è¡¨å•éƒ¨åˆ† - ä½¿ç”¨å›è°ƒå‡½æ•°è€Œä¸æ˜¯ç›´æ¥åœ¨è¡¨å•ä¸­å¤„ç†
    def search_papers():
        query = st.session_state.search_query
        max_results = st.session_state.max_results
        sort_by = st.session_state.sort_by
        auto_translate = st.session_state.auto_translate
        use_backup = st.session_state.use_backup
        
        with st.spinner("æœç´¢ä¸­..."):
            translated_query = query
            translation_performed = False
            
            # å¦‚æœéœ€è¦ç¿»è¯‘æŸ¥è¯¢ï¼ˆåŒ…å«ä¸­æ–‡ï¼‰
            if auto_translate and contains_chinese(query):
                translated_query, translation_performed = translate_to_english(query)
                
            if translation_performed:
                st.info(f"å·²å°†æœç´¢å…³é”®è¯ç¿»è¯‘ä¸º: \"{translated_query}\"")
                
            # æ‰§è¡Œæœç´¢
            results = arxiv_client.search(translated_query, max_results=max_results, sort_by=sort_by, use_backup=use_backup)
            
            # å°†æœç´¢ç»“æœä¿å­˜åˆ°session_stateä»¥ä¾¿åç»­ä½¿ç”¨
            st.session_state.search_results = results
            
            # å°†ç»“æœè½¬æ¢ä¸ºDataFrameä»¥ä¾¿æ˜¾ç¤º
            df_data = []
            for paper in results:
                # æ·»åŠ æ¥æºæ ‡è®°
                source_label = "[ArXiv]" if paper.get('source', '') == 'arxiv' else "[CrossRef]" if paper.get('source', '') == 'crossref' else ""
                
                # ç¡®ä¿æœ‰URLå­—æ®µ
                if 'url' not in paper and paper.get('id'):
                    arxiv_id = paper.get('id')
                    if arxiv_id.startswith('arxiv:'):
                        arxiv_id = arxiv_id[6:]
                    paper['url'] = f"https://arxiv.org/abs/{arxiv_id}"
                    paper['pdf_url'] = f"https://arxiv.org/pdf/{arxiv_id}.pdf"
                
                df_data.append({
                    "ID": paper['id'],
                    "æ¥æº": source_label,
                    "æ ‡é¢˜": paper['title'],
                    "ä½œè€…": ', '.join(paper['authors']) if isinstance(paper['authors'], list) else paper['authors'],
                    "å‘å¸ƒæ—¥æœŸ": paper['published'].split()[0] if isinstance(paper['published'], str) else paper['published'],
                    "åˆ†ç±»": ', '.join(paper['categories']) if isinstance(paper['categories'], list) else paper['categories']
                })
            
            st.session_state.df_data = df_data

    # åˆå§‹åŒ–session_stateå˜é‡
    if 'search_query' not in st.session_state:
        st.session_state.search_query = ""
    if 'max_results' not in st.session_state:
        st.session_state.max_results = 10
    if 'sort_by' not in st.session_state:
        st.session_state.sort_by = "relevance"
    if 'auto_translate' not in st.session_state:
        st.session_state.auto_translate = True
    if 'use_backup' not in st.session_state:
        st.session_state.use_backup = True

    # æœç´¢è¾“å…¥å­—æ®µ - ä¸ä½¿ç”¨è¡¨å•
    st.text_input("æœç´¢è®ºæ–‡", value="", key="search_query", help="è¾“å…¥å…³é”®è¯ï¼Œä¾‹å¦‚ï¼šquantum computing")

    # æœç´¢é€‰é¡¹
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.number_input("æœ€å¤§ç»“æœæ•°", min_value=5, max_value=100, value=10, key="max_results")
    with col2:
        st.selectbox("æ’åºæ–¹å¼", ["relevance", "lastUpdatedDate", "submittedDate"], key="sort_by")
    with col3:
        st.checkbox("è‡ªåŠ¨ç¿»è¯‘æŸ¥è¯¢", value=True, key="auto_translate")
    with col4:
        st.checkbox("ä½¿ç”¨å¤‡ç”¨æº", value=True, key="use_backup", help="å¦‚æœArXivç»“æœè¾ƒå°‘ï¼Œè‡ªåŠ¨ä½¿ç”¨å…¶ä»–å­¦æœ¯æœç´¢æº")

    # æœç´¢æŒ‰é’® - ä¸åœ¨è¡¨å•å†…
    if st.button("æœç´¢", key="search_button"):
        search_papers()

    # æ˜¾ç¤ºæœç´¢ç»“æœ
    if 'df_data' in st.session_state and st.session_state.df_data:
        df_data = st.session_state.df_data
        results = st.session_state.search_results
        
        st.write(f"æ‰¾åˆ° {len(df_data)} ç¯‡è®ºæ–‡:")
        
        # ä½¿ç”¨è¡¨æ ¼å±•ç¤ºç®€è¦ä¿¡æ¯
        df = pd.DataFrame(df_data)
        st.dataframe(df)
        
        # åˆ›å»ºé€‰æ‹©æ¡† - ä¸åœ¨è¡¨å•å†…
        paper_options = {f"{paper['id']} - {paper['title'][:50]}...": paper['id'] for paper in results}
        
        # å®šä¹‰é€‰æ‹©è®ºæ–‡æ—¶çš„å›è°ƒå‡½æ•°
        def on_paper_select():
            # ä»é€‰æ‹©æ¡†çš„å€¼ä¸­è·å–è®ºæ–‡ID
            selected_option = st.session_state.paper_selector
            paper_id = paper_options[selected_option]
            # æ›´æ–°selected_paper_id
            st.session_state.selected_paper_id = paper_id

        # ä½¿ç”¨on_changeå‚æ•°æŒ‡å®šå›è°ƒå‡½æ•°
        selected_paper_option = st.selectbox(
            "é€‰æ‹©è®ºæ–‡æŸ¥çœ‹è¯¦æƒ…", 
            list(paper_options.keys()),
            key="paper_selector",
            on_change=on_paper_select  # å½“é€‰æ‹©å˜åŒ–æ—¶è°ƒç”¨å›è°ƒå‡½æ•°
        )
        
        # ä¸å†éœ€è¦æŸ¥çœ‹è¯¦æƒ…æŒ‰é’®ï¼Œå› ä¸ºé€‰æ‹©è®ºæ–‡æ—¶ä¼šè‡ªåŠ¨è·å–è¯¦æƒ…
        # ä½†å¯ä»¥ä¿ç•™æŒ‰é’®ç”¨äºé‡æ–°åŠ è½½è¯¦æƒ…
        if st.button("é‡æ–°åŠ è½½è¯¦æƒ…", key="reload_details_button"):
            # è¿™é‡Œä¸éœ€è¦åšä»»ä½•äº‹æƒ…ï¼Œå› ä¸ºStreamlitä¼šè‡ªåŠ¨é‡æ–°è¿è¡Œè„šæœ¬
            pass

    # æ˜¾ç¤ºé€‰å®šè®ºæ–‡è¯¦æƒ… - ä¸åœ¨è¡¨å•å†…
    if st.session_state.selected_paper_id:
        paper_id = st.session_state.selected_paper_id
        with st.spinner("è·å–è®ºæ–‡è¯¦æƒ…..."):
            paper = arxiv_client.get_paper_details(paper_id)
            
            if "error" not in paper:
                # åœ¨session_stateä¸­å­˜å‚¨å½“å‰è®ºæ–‡è¯¦æƒ…
                st.session_state.current_paper = paper
                
                # ä½¿ç”¨ä¸¤åˆ—å¹¶æ’æ˜¾ç¤ºä¸­è‹±æ–‡å†…å®¹
                col_en, col_zh = st.columns(2)
                
                # è‹±æ–‡åŸæ–‡æ˜¾ç¤º
                with col_en:
                    st.markdown("### Original")
                    st.markdown(f"**Title:** {paper['title']}")
                    st.markdown(f"**Authors:** {', '.join(paper['authors'])}")
                    st.markdown(f"**Published:** {paper['published']}")
                    
                    # å…ƒæ•°æ® - è‹±æ–‡
                    if 'citation_count' in paper:
                        st.markdown(f"**Citations:** {paper['citation_count']}")
                    if 'influence_factor' in paper:
                        st.markdown(f"**Influence Factor:** {paper['influence_factor']}")
                    if 'published_in' in paper and paper['published_in'] != 'æœªçŸ¥':
                        st.markdown(f"**Published in:** {paper['published_in']}")
                    
                    # åˆ†ç±» - è‹±æ–‡
                    st.markdown(f"**Categories:** {', '.join(paper['categories']) if isinstance(paper['categories'], list) else paper['categories']}")
                    
                    # æ‘˜è¦ - è‹±æ–‡
                    st.markdown("### Abstract")
                    st.markdown(paper['summary'])
                
                # ä¸­æ–‡ç¿»è¯‘æ˜¾ç¤º
                with col_zh:
                    st.markdown("### ä¸­æ–‡ç¿»è¯‘")
                    st.markdown(f"**æ ‡é¢˜:** {safe_get(paper, 'title_zh', paper['title'])}")
                    st.markdown(f"**ä½œè€…:** {', '.join(paper['authors'])}")
                    st.markdown(f"**å‘å¸ƒæ—¥æœŸ:** {paper['published']}")
                    
                    # å…ƒæ•°æ® - ä¸­æ–‡
                    if 'citation_count' in paper:
                        st.markdown(f"**å¼•ç”¨æ¬¡æ•°:** {paper['citation_count']}")
                    if 'influence_factor' in paper:
                        st.markdown(f"**å½±å“å› å­:** {paper['influence_factor']}")
                    if 'published_in' in paper and paper['published_in'] != 'æœªçŸ¥':
                        st.markdown(f"**å‘è¡¨äº:** {paper['published_in']}")
                    
                    # åˆ†ç±» - ä¸­æ–‡  
                    st.markdown(f"**åˆ†ç±»:** {', '.join(paper['categories']) if isinstance(paper['categories'], list) else paper['categories']}")
                    
                    # æ‘˜è¦ - ä¸­æ–‡
                    st.markdown("### æ‘˜è¦")
                    st.markdown(safe_get(paper, 'summary_zh', paper['summary']))
                
                # ä¸»é¢˜æ ‡ç­¾ (å¦‚æœæœ‰)
                if 'topics' in paper and paper['topics']:
                    st.markdown("### ä¸»é¢˜ / Topics")
                    tags = paper['topics']
                    st.write(' '.join([f"<span style='background-color: #E6F6FF; padding: 2px 8px; border-radius: 12px; margin-right: 8px;'>{tag}</span>" for tag in tags]), unsafe_allow_html=True)
                
                # åˆ†éš”çº¿
                st.markdown("---")
                
                # æ·»åŠ è®ºæ–‡é“¾æ¥åŒºåŸŸ
                st.markdown("### è®ºæ–‡é“¾æ¥")
                link_col1, link_col2, = st.columns(2)
                
                with link_col1:
                    # åœ¨çº¿æŸ¥çœ‹PDFæŒ‰é’®
                    pdf_url = None
                    if paper.get('source') == 'crossref':
                        # CrossRefè®ºæ–‡çš„URL
                        pdf_url = paper.get('url')
                    else:
                        # ArXivè®ºæ–‡çš„PDF URL
                        if paper.get('id'):
                            arxiv_id = paper.get('id')
                            # ç§»é™¤å¯èƒ½çš„'arxiv:'å‰ç¼€
                            if arxiv_id.startswith('arxiv:'):
                                arxiv_id = arxiv_id[6:]
                            pdf_url = f"https://arxiv.org/pdf/{arxiv_id}.pdf"
                    
                    if pdf_url:
                        st.markdown(f"[åœ¨çº¿æŸ¥çœ‹PDF]({pdf_url})")
                
                with link_col2:
                    # ArXivé¡µé¢é“¾æ¥
                    arxiv_url = None
                    if paper.get('id') and not paper.get('id').startswith('doi:'):
                        arxiv_id = paper.get('id')
                        # ç§»é™¤å¯èƒ½çš„'arxiv:'å‰ç¼€
                        if arxiv_id.startswith('arxiv:'):
                            arxiv_id = arxiv_id[6:]
                        arxiv_url = f"https://arxiv.org/abs/{arxiv_id}"
                        st.markdown(f"[æŸ¥çœ‹ArXivé¡µé¢]({arxiv_url})")
                    elif paper.get('arxiv_url'):
                        st.markdown(f"[æŸ¥çœ‹ArXivé¡µé¢]({paper.get('arxiv_url')})")
                    elif paper.get('source') == 'crossref' and paper.get('doi'):
                        doi = paper.get('doi')
                        doi_url = f"https://doi.org/{doi}" if not doi.startswith('http') else doi
                        st.markdown(f"[æŸ¥çœ‹DOIé¡µé¢]({doi_url})")
                
                # æ·»åŠ åµŒå…¥å¼PDFæŸ¥çœ‹å™¨
                st.markdown("### é¢„è§ˆ")
                
                # ä¸ºPDFåˆ›å»ºä¸€ä¸ªåµŒå…¥å¼æ¡†æ¶
                if pdf_url:
                    # ä½¿ç”¨HTML iframeåµŒå…¥PDF
                    pdf_display = f"""
                    <iframe src="{pdf_url}" width="100%" height="600" style="border:none;"></iframe>
                    """
                    st.markdown(pdf_display, unsafe_allow_html=True)
                    st.markdown("*å¦‚æœPDFåŠ è½½å¤±è´¥ï¼Œè¯·ä½¿ç”¨ä¸Šæ–¹é“¾æ¥ç›´æ¥è®¿é—®*")
                else:
                    st.info("æ— æ³•é¢„è§ˆPDFï¼Œè¯·ä½¿ç”¨é“¾æ¥åœ¨çº¿æŸ¥çœ‹æˆ–ä¸‹è½½åæŸ¥çœ‹")
                
                # åˆ†éš”çº¿
                st.markdown("---")
                
                # æ·»åŠ ä¸‹è½½å’Œæ”¶è—æŒ‰é’®åŒºåŸŸ
                st.markdown("### æ“ä½œ")
                action_col1, action_col2 = st.columns(2)
                
                with action_col1:
                    # ä¸‹è½½æŒ‰é’®å®ç°
                    if paper['id'] not in st.session_state.download_states:
                        if st.button("ğŸ“¥ ä¸‹è½½æ­¤è®ºæ–‡", key=f"download_button_{paper['id']}"):
                            # åˆå§‹åŒ–ä¸‹è½½çŠ¶æ€
                            st.session_state.download_states[paper['id']] = "initialized"
                            st.session_state.download_messages[paper['id']] = "æ­£åœ¨å‡†å¤‡ä¸‹è½½..."
                            
                            # åˆ›å»ºå¹¶å¯åŠ¨ä¸‹è½½çº¿ç¨‹
                            download_thread = threading.Thread(
                                target=download_paper_async,
                                args=(paper['id'],)
                            )
                            # æ·»åŠ è„šæœ¬è¿è¡Œä¸Šä¸‹æ–‡ä»¥å…è®¸çº¿ç¨‹å†…æ›´æ–°session_state
                            ctx = get_script_run_ctx()
                            add_script_run_ctx(download_thread)
                            download_thread.start()
                
                with action_col2:
                    # æ·»åŠ æ”¶è—æŒ‰é’®
                    if st.button("â­ æ·»åŠ åˆ°æ”¶è—", key=f"favorite_{paper['id']}"):
                        try:
                            # ç¡®ä¿é»˜è®¤åˆ†ç±»å­˜åœ¨
                            if "æ”¶è—" not in paper_manager.get_categories():
                                paper_manager.add_category("æ”¶è—")
                            
                            # æ·»åŠ åˆ°æ”¶è—åˆ†ç±»
                            # å…ˆç¡®ä¿è®ºæ–‡å·²ä¿å­˜
                            if paper_manager.get_paper(paper['id']) is None:
                                # å¦‚æœè®ºæ–‡æœªä¿å­˜ï¼Œå…ˆæ·»åŠ åˆ°è®ºæ–‡åˆ—è¡¨
                                local_path = paper.get('local_path', '')
                                paper_manager.add_paper(paper, local_path)
                            
                            # æ·»åŠ åˆ°æ”¶è—åˆ†ç±»
                            paper_manager.add_paper_to_category(paper['id'], "æ”¶è—")
                            st.success("å·²æ·»åŠ åˆ°æ”¶è—")
                        except Exception as fav_err:
                            st.error(f"æ·»åŠ åˆ°æ”¶è—å¤±è´¥: {str(fav_err)}")
            else:
                st.error(paper["error"])

elif option == "ä¸‹è½½è®ºæ–‡":
    st.header("æ‰¹é‡ä¸‹è½½è®ºæ–‡")
    
    # æ‰¹é‡ä¸‹è½½è¡¨å•
    with st.form(key='download_form'):
        paper_ids = st.text_area("è¾“å…¥è®ºæ–‡IDï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", height=150, help="è¾“å…¥ArXivè®ºæ–‡IDï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¾‹å¦‚: 2106.14572")
        download_button = st.form_submit_button("ä¸‹è½½è®ºæ–‡")
        
        if download_button and paper_ids:
            # åˆ†å‰²è¾“å…¥çš„ID
            ids = [id.strip() for id in paper_ids.split('\n') if id.strip()]
            
            if ids:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                downloaded_papers = []
                failed_papers = []
                
                for i, paper_id in enumerate(ids):
                    status_text.text(f"ä¸‹è½½ä¸­ ({i+1}/{len(ids)}): {paper_id}")
                    try:
                        output_path = arxiv_client.download(paper_id)
                        downloaded_papers.append((paper_id, output_path))
                    except Exception as e:
                        failed_papers.append((paper_id, str(e)))
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    progress_bar.progress((i + 1) / len(ids))
                
                # æ˜¾ç¤ºç»“æœ
                if downloaded_papers:
                    st.success(f"æˆåŠŸä¸‹è½½ {len(downloaded_papers)} ç¯‡è®ºæ–‡")
                    for paper_id, path in downloaded_papers:
                        st.write(f"- {paper_id}: {path}")
                
                if failed_papers:
                    st.error(f"ä¸‹è½½å¤±è´¥ {len(failed_papers)} ç¯‡è®ºæ–‡")
                    for paper_id, error in failed_papers:
                        st.write(f"- {paper_id}: {error}")
                        
elif option == "æ•´ç†è®ºæ–‡":
    st.header("æ•´ç†ä¸‹è½½çš„è®ºæ–‡")
    
    # è·å–æ‰€æœ‰å·²ä¸‹è½½çš„è®ºæ–‡
    papers = paper_manager.get_all_papers()  # ä½¿ç”¨æ–°æ·»åŠ çš„æ–¹æ³•
    if papers:
        st.subheader("å·²ä¸‹è½½çš„è®ºæ–‡")
        
        # è½¬æ¢ä¸ºé€‚åˆæ˜¾ç¤ºçš„æ ¼å¼
        paper_data = []
        for paper in papers:
            paper_data.append({
                "ID": paper.get('id', ''),
                "æ ‡é¢˜": paper.get('title', ''),
                "ä½œè€…": ', '.join(paper.get('authors', [])) if isinstance(paper.get('authors'), list) else paper.get('authors', ''),
                "ä¸‹è½½æ—¥æœŸ": paper.get('download_date', ''),
                "æœ¬åœ°è·¯å¾„": paper.get('local_path', '')
            })
        
        df = pd.DataFrame(paper_data)
        st.dataframe(df)
        
        # æ·»åŠ æœç´¢åŠŸèƒ½
        search_term = st.text_input("æœç´¢å·²ä¸‹è½½çš„è®ºæ–‡", "")
        if search_term:
            filtered_papers = [p for p in paper_data if 
                               search_term.lower() in p['æ ‡é¢˜'].lower() or 
                               search_term.lower() in p['ä½œè€…'].lower() or
                               search_term.lower() in p['ID'].lower()]
            if filtered_papers:
                st.write(f"æ‰¾åˆ° {len(filtered_papers)} ä¸ªåŒ¹é…ç»“æœ:")
                st.dataframe(pd.DataFrame(filtered_papers))
            else:
                st.info("æœªæ‰¾åˆ°åŒ¹é…çš„è®ºæ–‡")
        
        # æ·»åŠ åˆ†ç±»ç®¡ç†
        st.subheader("è®ºæ–‡åˆ†ç±»ç®¡ç†")
        
        # æ˜¾ç¤ºç°æœ‰åˆ†ç±»
        categories = paper_manager.get_categories()
        if categories:
            st.write("ç°æœ‰åˆ†ç±»:")
            for category in categories:
                st.write(f"- {category}")
        
        # æ·»åŠ æ–°åˆ†ç±»
        new_category = st.text_input("æ–°å»ºåˆ†ç±»")
        if st.button("æ·»åŠ åˆ†ç±»") and new_category:
            paper_manager.add_category(new_category)
            st.success(f"å·²æ·»åŠ åˆ†ç±»: {new_category}")
            st.experimental_rerun()
        
        # ä¸ºè®ºæ–‡æ·»åŠ åˆ†ç±»
        st.subheader("ä¸ºè®ºæ–‡æ·»åŠ åˆ†ç±»")
        paper_options = {f"{p['ID']} - {p['æ ‡é¢˜'][:50]}...": p['ID'] for p in paper_data}
        selected_paper = st.selectbox("é€‰æ‹©è®ºæ–‡", list(paper_options.keys()))
        selected_paper_id = paper_options[selected_paper] if selected_paper else None
        
        if selected_paper_id and categories:
            selected_category = st.selectbox("é€‰æ‹©åˆ†ç±»", categories)
            if st.button("æ·»åŠ åˆ°åˆ†ç±»") and selected_category:
                paper_manager.add_paper_to_category(selected_paper_id, selected_category)
                st.success(f"å·²å°†è®ºæ–‡æ·»åŠ åˆ°åˆ†ç±»: {selected_category}")
        
        # æŸ¥çœ‹åˆ†ç±»ä¸‹çš„è®ºæ–‡
        st.subheader("æŸ¥çœ‹åˆ†ç±»")
        if categories:
            view_category = st.selectbox("é€‰æ‹©è¦æŸ¥çœ‹çš„åˆ†ç±»", categories, key="view_category")
            if view_category:
                category_papers = paper_manager.get_papers_by_category(view_category)
                if category_papers:
                    st.write(f"{view_category} åˆ†ç±»ä¸‹çš„è®ºæ–‡:")
                    
                    # å°†åˆ†ç±»ä¸‹çš„è®ºæ–‡è½¬æ¢ä¸ºDataFrame
                    cat_paper_data = []
                    for paper_id in category_papers:
                        paper = paper_manager.get_paper(paper_id)
                        if paper:
                            cat_paper_data.append({
                                "ID": paper.get('id', ''),
                                "æ ‡é¢˜": paper.get('title', ''),
                                "ä½œè€…": ', '.join(paper.get('authors', [])),
                                "ä¸‹è½½æ—¥æœŸ": paper.get('download_date', '')
                            })
                    
                    if cat_paper_data:
                        st.dataframe(pd.DataFrame(cat_paper_data))
                    else:
                        st.info(f"{view_category} åˆ†ç±»ä¸‹æš‚æ— è®ºæ–‡")
                else:
                    st.info(f"{view_category} åˆ†ç±»ä¸‹æš‚æ— è®ºæ–‡")
    else:
        st.info("æš‚æ— ä¸‹è½½çš„è®ºæ–‡ã€‚è¯·å…ˆä½¿ç”¨\"ä¸‹è½½è®ºæ–‡\"åŠŸèƒ½ä¸‹è½½ä¸€äº›è®ºæ–‡ã€‚")